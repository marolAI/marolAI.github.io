<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>My portfolio</title>

  <!-- CSS Files -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- JS files-->  
  <script scr="assets/js/script.js" type="text/javascript"></script>
</head>

<body>
    <!-- ============= About ============== -->
    <section id="about">
        <div class="container"></div>
            <div class="intro">
                <div class="avatar">
                    <img src="assets/img/profile.jpg">
                </div>
                <div class="title">
                    <h3>Andriamarolahy Rabetokotany</h3>
                    <h5>Data Scientist</h5>
                    <div class="social-icons">
                        <a href="https://www.linkedin.com/in/andriamarolahy-rabetokotany-a84986143/">
                            <i class="fa fa-linkedin fa-lg fa-fw"></i>
                        </a>
                        <a href="https://github.com/marolAI">
                            <i class="fa fa-github fa-lg fa-fw"></i>
                        </a>
                        <a href="https://twitter.com/Massa_Be">
                            <i class="fa fa-twitter fa-lg fa-fw"></i>
                        </a>
                        <a href="https://stackoverflow.com/users/9560986/r-marolahy">
                            <i class="fa fa-stack-overflow fa-lg fa-fw"></i>
                        </a>
                    </div>
                </div>
                <div class="bio">
                    <p>I use data and machine learning to solve business problems. I enjoy learning new things.</p>
                    <ul class="tags">
                        <li><a href="#" class="tag">SQL</a></li>
                        <li><a href="#" class="tag">Python</a></li>
                        <li><a href="#" class="tag">Data Analysis</a></li>
                        <li><a href="#" class="tag">Data Visualization</a></li>
                        <li><a href="#" class="tag">Machine Learning</a></li>
                    </ul>
                </div>
            </div>
        </div>
        <!-- <div class="arrow">
            <h6>Projects</h6>
            <a href="#projects" class="scroll-down" address="true"></a>
        </div> -->
    </section>

    <!-- ============= Projects ============== -->
    <section id="projects">
        <div class="container">
            <div class="col-12">
                <h2><i>Projects</i></h2>
                <hr class="mb-4">
            </div>
            <div class="row">
                <div class="card">
                    <div class="card-header">
                        <img src="assets/img/portfolio/BERT-VQA.png" alt="vqa-bert" />
                    </div>
                    <div class="card-body">
                        <h5>
                            Evaluating Modern Language-Only Baseline (BERT) for Visual Question Answering (VQA)
                        </h5>
                        <a target="_blank" rel="noopener noreferrer" href="https://github.com/marolAI/VQA-BERT" title="Read Full">
                            <i class="fa fa-github fa-fw"></i>
                        </a>
                        <a target="_blank" rel="noopener noreferrer"
                            href="https://github.com/marolAI/VQA-BERT/blob/main/report/vqa-bert.pdf" title="Read Full">
                            <i class="fa fa-link fa-fw"></i>
                        </a>
                        <p>
                            VQA is the task consists of answering natural language questions about any given image. When the task was originally 
                            released in 2015, deep sequence models like RNNs, LSTMs, GRUs over pretrained word-embeddings (word2vec, GloVE) were used to 
                            design question-only baselines. Since then, large scale pretrained language models like Bidirectional Encoder Representation from 
                            Transformers are involved. The aim of this project is to retrain and evaluate the performance of a language-only baseline VQA model using BERT.
                        </p>
                        <!-- <span class="tag tag-pink">Design</span> -->
                    </div>
                    <div class="card-footer">
                        <ul class="tags">
                            <li><a href="#" class="tag">Python</a></li>
                            <li><a href="#" class="tag">Deep Learning</a></li>
                            <li><a href="#" class="tag">BERT</a></li>
                            <li><a href="#" class="tag">VQA</a></li>
                        </ul>
                    </div>
                </div>
                <div class="card">
                    <div class="card-header">
                        <img src="assets/img/portfolio/mixup_SMOTE1.png" alt="mixup_SMOTE1" />
                    </div>
                    <div class="card-body">
                        <h5>
                            Robust Machine Learning With Imbalanced Data: Expanding Mixup
                        </h5>
                        <a target="_blank" rel="noopener noreferrer" href="https://github.com/marolAI/Expanding-Mixup" title="Read Full">
                            <i class="fa fa-github fa-fw"></i>
                        </a>
                        <a target="_blank" rel="noopener noreferrer"
                            href="https://github.com/marolAI/Expanding-Mixup/blob/main/report/mixup.pdf" title="Read Full">
                            <i class="fa fa-link fa-fw"></i>
                        </a>
                        <p>
                           Imbalanced learning is a subfield of Machine Learning which consists of learning from imbalanced data. Synthetic Minority Oversampling
                           Technique (SMOTE) is one of the best techniques to approach this issue. However it still exhibits poor prediction toward minority class when data
                           is highly skewed and outside the training data. This relates to the fact that we use Empirical Risk Minimization (ERM) technique to train the model.
                           Mixup is one of the prominent algorithm that can mitigate this drawback of ERM. The aim of this project is to combine the advantages of both SMOTE 
                           and Mixup to predict fraudulant transactions on a very imbalanced credit card transactions dataset.
                        </p>
                        <!-- <span class="tag tag-pink">Design</span> -->
                    </div>
                    <div class="card-footer">
                        <ul class="tags">
                            <li><a href="#" class="tag">Python</a></li>
                            <li><a href="#" class="tag">Machine Learning</a></li>
                            <li><a href="#" class="tag">SMOTE</a></li>
                            <li><a href="#" class="tag">ERM</a></li>
                            <li><a href="#" class="tag">Mixup</a></li>
                        </ul>
                    </div>
                </div>
                <div class="card">
                    <div class="card-header">
                        <img src="assets/img/portfolio/smart_identity.png" alt="smart_identity"/>
                    </div>
                    <div class="card-body">
                        <h5>
                            Smart Identity: classify and extract personal information from the ECOWAS ID card.
                        </h5>
                        <a target="_blank" rel="noopener noreferrer" href="https://github.com/marolAI/Smart-Identity" title="Read Full">
                            <i class="fa fa-github fa-fw"></i>
                        </a>
                        <p>
                            Paper-based document processing is one of the major problems in the industry. In addition to the human resources it requires, 
                            the time it takes can be frustrating and wasteful. The goal of this project is to automate the process of extracting personal information 
                            from the ECOWAS ID card using a model based on CNN for classification and Pytesseract for OCR.
                        </p>
                        <!-- <span class="tag tag-pink">Design</span> -->
                    </div>
                    <div class="card-footer">
                        <ul class="tags">
                            <li><a href="#" class="tag">Python</a></li>
                            <li><a href="#" class="tag">CNN</a></li>
                            <li><a href="#" class="tag">OCR</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- ============= Contacts ============== -->
    <!-- <section id="contact">
        <div class="container">
            <div class="col-12">
                <h2><i>Contact</i></h2>
                <hr class="mb-4">
            </div>


        </div>
    </section> -->
</body>
</html>